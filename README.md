论文阅读笔记：

目录—>`README.MD ` 

笔记—>`/Summray`

# 目录

## LegalAI

### Survey


### Dataset

### Legal Judgment Prediction


### Court View Generation

### Similar Case Match

### LLM in Law

DISC-LawLLM: Fine-tuning Large Language Models for Intelligent Legal Services,2023. [[paper](https://arxiv.org/abs/2309.11325)]

Lawyer LLaMA Technical Report,2023.[[paper](https://arxiv.org/abs/2305.15062)]

### Study

A Comprehensive Evaluation of Large Language Models on Legal Judgment Prediction,2023. [[paper](https://aclanthology.org/2023.findings-emnlp.490/)]

LawBench: Benchmarking Legal Knowledge of Large Language Models,2023. [[paper](https://arxiv.org/abs/2309.16289)]

LAiW: A Chinese Legal Large Language Models Benchmark,2024. [[paper](https://openreview.net/pdf?id=HEjqNfHCCH)]

TruthfulQA: Measuring How Models Mimic Human Falsehoods,2022. [[paper](https://aclanthology.org/2022.acl-long.229.pdf)]

**Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models,2024.** [[paper](https://arxiv.org/abs/2401.01301)]

## Large Language Model

### Survey


### Models
QWEN TECHNICAL REPORT [[paper](https://arxiv.org/abs/2309.16609)]

GLM: General Language Model Pretraining with Autoregressive Blank Infilling [[paper](https://aclanthology.org/2022.acl-long.26.pdf)]


LLaMA: Open and Efficient Foundation Language Models [[paper](https://arxiv.org/abs/2302.13971)]

Llama 2: Open Foundation and Fine-Tuned Chat Models [[paper](https://arxiv.org/abs/2307.09288)]

Introducing Meta Llama 3: The most capable openly available LLM to date [[paper](https://ai.meta.com/blog/meta-llama-3/)]

### Retriever Argument Generation（RAG）


### PLan-then-Generate
Plan-then-Generate: Controlled Data-to-Text Generation via Planning,2021[[paper](https://aclanthology.org/2021.findings-emnlp.76/)]


### Chain-of-Thought (CoT)

Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework,2023. [[paper](https://aclanthology.org/2023.acl-long.320.pdf)]

Chain of Thought Prompting Elicits Knowledge Augmentation,2023.[[paper](https://aclanthology.org/2023.findings-acl.408.pdf)]

### Hallucination

**Evaluating Hallucinations in Chinese Large Language Models,2023.** [[paper](https://arxiv.org/abs/2310.03368)]

**TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization,2024.**[[paper](https://arxiv.org/abs/2402.13249)]

**Exploring and Evaluating Hallucinations in LLM-Powered Code Generation,2024.** [[paper](https://arxiv.org/abs/2404.00971)]

UHGEval: Benchmarking the Hallucination of
Chinese Large Language Models via Unconstrained Generation,2024.[[paper](https://arxiv.org/abs/2311.15296)]

Hallucination Detection: Robustly Discerning Reliable Answers in Large Language Models,2023.[[paper](https://dl.acm.org/doi/pdf/10.1145/3583780.3614905)]

The Internal State of an LLM Knows When It's Lying,2023. [[paper](https://arxiv.org/abs/2304.13734)]

### LLM interpretation



## Other

DeepChannel: Salience Estimation by Contrastive Learning
for Extractive Document Summarization,2018.[[paper](https://arxiv.org/abs/1811.02394)]

Element-aware Summarization with Large Language Models:
Expert-aligned Evaluation and Chain-of-Thought Method,2023. [[paper](https://aclanthology.org/2023.acl-long.482.pdf)]

Rethinking Interpretability in the Era of Large Language Models,2024.[[paper](https://arxiv.org/abs/2402.01761)]